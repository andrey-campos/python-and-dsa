{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5419b4bb",
   "metadata": {},
   "source": [
    "# Fluent Python - CH2\n",
    "\n",
    "## Unpacking Iterables and Sequences\n",
    "\n",
    "Unpacking items from iterables and sequences is useful because it avoids error prone indexing. Also **indexing doesn't work with iterators..**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "39e480cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33.934"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# parallel assignment in unpacking\n",
    "lax_cords = (33.934, -118.93902)\n",
    "lat, long = lax_cords # unpacking\n",
    "lat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "4cb177f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-118.93902"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# also elegant swapping\n",
    "lat, long = long, lat\n",
    "lat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0601bb5",
   "metadata": {},
   "source": [
    "### Using * To Grab Excess Items \n",
    "\n",
    "Defining function parameters with `*args` to grab arbitrary excess arguments is classic python feature\n",
    "\n",
    "In fact in Python3, this idea was extended to apply to parallel assignment too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "25196046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 1, [2, 3, 4])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grabbing excess arguments from range - turns to list\n",
    "a, b, *rest = range(5)\n",
    "a, b, rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "fa46b496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 3, 4, (5, 6))"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fun(a, b, c, d, *rest):\n",
    "    return a, b, c, d, rest\n",
    "\n",
    "# notice unpacks until 'd' index then makes tuple for --\n",
    "# unpacking rest of elements in range(i, n)\n",
    "fun(*[1, 2], 3, *range(4, 7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "33495a33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2, 3, 4, 5, 6, 7}"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# can even do this to define list, tuple, or set literals\n",
    "{*range(4), 4, *[5, 6, 7]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2115ef0",
   "metadata": {},
   "source": [
    "### Nested Unpacking \n",
    "Nested Unpacking can be crucial for nested data types\n",
    "\n",
    "e.g. `(a, b, (c, d))` \n",
    "\n",
    "We need Python to properly handle these structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "fa47b2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# consider this nested data structure with useful info\n",
    "metro_areas = [\n",
    "('Tokyo', 'JP', 36.933, (35.689722, 139.691667)),\n",
    "('Delhi NCR', 'IN', 21.935, (28.613889, 77.208889)),\n",
    "('Mexico City', 'MX', 20.142, (19.433333,\n",
    "-99.133333)),\n",
    "('New York-Newark', 'US', 20.104, (40.808611,\n",
    "-74.020386)),\n",
    "('São Paulo', 'BR', 19.649, (-23.547778,\n",
    "-46.635833)),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "93466d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mexico City     |   19.4333 |  -99.1333\n",
      "New York-Newark |   40.8086 |  -74.0204\n",
      "São Paulo       |  -23.5478 |  -46.6358\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    for name, _, _, (lat, lon) in metro_areas:\n",
    "        if lon <= 0:\n",
    "            print(f\"{name:15} | {lat:9.4f} | {lon:9.4f}\")\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bdbebde",
   "metadata": {},
   "source": [
    "### Match and Case Syntax and Sequences \n",
    "\n",
    "This `match/case` syntax is perfect for a alternative and more readable `if/elif/else` statement\n",
    "\n",
    "the `case pattern1` can handle many types of patterns.\n",
    "\n",
    "1. `pattern1 = \"hello\"` \n",
    "2. `pattern1 = _` this is a wildcard pattern, acts as the default case.\n",
    "3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "c669312e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Integer: 10\n",
      "Long String: Hello World\n",
      "List with head: 1 and tail: [2, 3]\n",
      "Name: Alice, age 10\n"
     ]
    }
   ],
   "source": [
    "def process_data(data):\n",
    "    match data:\n",
    "        case int(x) if x > 0:\n",
    "            print(f\"Positive Integer: {x}\")\n",
    "\n",
    "        case str(s) if len(s) > 5:\n",
    "            print(f\"Long String: {s}\")\n",
    "\n",
    "        case [head, *tail]:\n",
    "            print(f\"List with head: {head} and tail: {tail}\")\n",
    "        \n",
    "        case {\"name\": name, \"age\": age}:\n",
    "            print(f\"Name: {name}, age {age}\")\n",
    "\n",
    "        case _:\n",
    "            print(\"Unknown data or pattern.\")\n",
    "\n",
    "process_data(10)\n",
    "process_data(\"Hello World\")\n",
    "process_data([1, 2, 3])\n",
    "process_data({\"name\": \"Alice\", \"age\": 10})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826e7d62",
   "metadata": {},
   "source": [
    "As you can see as well we can make patterns even more specific by adding type information.\n",
    "\n",
    "`case[str(name), _, _, (float(lat), float(lon))]`\n",
    "\n",
    "These **AREN'T** constructor calls, they're a **runtime type check**, have they manage to fail this runtime check it doesn't match the case so no error pops up..\n",
    "\n",
    "On the surface this looks like a `switch/case` from JavaScript or C language but one key improvement from `switch` is **destructing**--a more advanced form of unpacking. Let's use our previous `metro_area` example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "f44dbbd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mexico City     |   19.4333 |  -99.1333\n",
      "New York-Newark |   40.8086 |  -74.0204\n",
      "São Paulo       |  -23.5478 |  -46.6358\n"
     ]
    }
   ],
   "source": [
    "# Using regular if/elif syntax\n",
    "def main():\n",
    "    for name, _, _, (lat, lon) in metro_areas:\n",
    "        if lon <= 0:\n",
    "            print(f\"{name:15} | {lat:9.4f} | {lon:9.4f}\")\n",
    "\n",
    "\n",
    "# Using match/case\n",
    "def main():\n",
    "    for record in metro_areas:\n",
    "        match record:\n",
    "            # runs only if pattern matches and guard expression is truthy\n",
    "            case [str(name), _, _, (lat, lon)] if lon <= 0:\n",
    "                print(f\"{name:15} | {lat:9.4f} | {lon:9.4f}\")\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d044bc2a",
   "metadata": {},
   "source": [
    "**Notice two crucial things.**\n",
    "\n",
    "1. The subject of this match is `record` -- i.e, each of the tuples in `metro_areas`\n",
    "\n",
    "2.  A `case` clause has two parts:\n",
    "\n",
    "    2.1 A pattern\n",
    "\n",
    "    2.2 An optional guard with the `if` keyword\n",
    "    \n",
    "\n",
    "For our case, a sequence pattern matches the subject if:\n",
    "1. The subject if a sequence and, \n",
    "2. THe subject and the pattern have the same number of items and,\n",
    "3. Each corresponding item matches, including nested items.\n",
    "\n",
    "**Warning**\n",
    "\n",
    "`str, bytes & bytearray` are not handled as sequences in the context of the `match/case` e.g. the int 987 is treated as an atomic value, not a sequence of digits. To handle them as a sequence subject, convert it in the `match` clause. For ex. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "245feb5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 0 0 3 0 0 1 0 0 0\n"
     ]
    }
   ],
   "source": [
    "phone = \"16003001000\" # ex. +1 U.S phone number\n",
    "\n",
    "# only works for strs, bytes, and bytearrays\n",
    "match list(phone):\n",
    "    case [\"1\", *rest]:\n",
    "        print(*rest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f8c7bd",
   "metadata": {},
   "source": [
    "### Inner Depths of Slicing in Python\n",
    "\n",
    "Pythonic convention of excluding the last item in slices and ranges work well with zero-based indexing used in Python, C.\n",
    "\n",
    "**Slice Objects**\n",
    "\n",
    "This is no secret but `s[a:b:c]` can be used to specify a stride or step `c`, causing the slice to skip items. The stride can also be negative. returning items in reverse. The 3 examples make this clear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "a4bc9069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bye\n",
      "elcycib\n",
      "eccb\n"
     ]
    }
   ],
   "source": [
    "s = 'bicycle'\n",
    "\n",
    "# skips by 3 to get next letter printed\n",
    "print(s[::3])\n",
    "\n",
    "# goes backwards to get the elements in reverse\n",
    "print(s[::-1])\n",
    "\n",
    "# prints first letter, then skips 1, prints next.\n",
    "print(s[::-2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab028ba",
   "metadata": {},
   "source": [
    "The notation `a:b:c` is only valid within `[]` when used as the indexing or subscript operator, and it produces a slice object: `slice(a, b, c)`.\n",
    "\n",
    "Later on we'll see how to evaluate the expression `seq[start:stop:step]`, Python calls `seq.__getitem__(start, stop, step))` Knowing about slice objects is useful b/c it lets you assign names to slices, just like spread sheets allowing naming of cell ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "184009cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "slice(0, 10, 5)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slicee = slice(0, 10, 5)\n",
    "slicee"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79bdd520",
   "metadata": {},
   "source": [
    "**Multidimensional Slicing and Ellipsis**\n",
    "\n",
    "The `[]` operator can also take multiple indexes or slices separated by commas. The `__getitem__` and `__setitem__` special methods that handle the `[]` operator simply recieve the indices in `a[i, j]` as a tuple. In other words, to evaluate `a[i, j]`, Python calls `a.__getitem__((i, j))`\n",
    "\n",
    "This is obviously used for packages like **numpy** where items of a 2d array `numpy.ndarray` can be fetched with the syntax:\n",
    "\n",
    "`a[i, j]` => i as index of row (axis 0), j is the index of column (axis, 1)\n",
    "\n",
    "However the rest of sequence types in Python are 1d, so they support one index or slice. **NOT** a tuple. (Except for `memoryview`) Basically `Ellipsis` <- (instance not class name btw) **are NOT used in standard Python library**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "2fb74cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  4  9 16]\n",
      "[16  9  4  1  0]\n",
      "<class 'numpy.ndarray'> (5,)\n"
     ]
    }
   ],
   "source": [
    "# Exploring some of my numpy's multi dimensional slicing\n",
    "import numpy as np\n",
    "\n",
    "# basically make a list range(0, 5) \n",
    "# then square each num \n",
    "a = np.arange(5) ** 2\n",
    "print(a)\n",
    "\n",
    "# more basic indexing a messing around with\n",
    "print(a[::-1])\n",
    "print(type(a), a.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6032e9",
   "metadata": {},
   "source": [
    "**Assigning to Slices**\n",
    "\n",
    "Mutable sequences can be changed in place using slice notation either by:\n",
    "\n",
    "1. On the lefthand side of an assignment statement \n",
    "\n",
    "2. As the target of a `del statement`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "ee4149b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "[0, 1, 20, 30, 5, 6, 7, 8, 9]\n",
      "[0, 1, 20, 30, 5, 8, 9]\n",
      "[0, 1, 20, 11, 5, 22, 9]\n"
     ]
    }
   ],
   "source": [
    "l = list(range(10))\n",
    "print(l)\n",
    "\n",
    "# place list between these indices \n",
    "# if we add something like 50, 5 stays..\n",
    "l[2:5] = [20, 30]\n",
    "print(l)\n",
    "\n",
    "# delete indices 5 and.6\n",
    "del l[5:7]\n",
    "print(l)\n",
    "\n",
    "l[3::2] = [11, 22]\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d58872",
   "metadata": {},
   "source": [
    "Note when the target of an assignment is a slice the right hand side **must** be an iterable object, even if it has just one item."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ae722e",
   "metadata": {},
   "source": [
    "**Using + and * with Sequences**\n",
    "\n",
    "Its expected that sequences support `+` and `*`. Usually both operands of `+` must be the same sequence type, and neither of them is modified but a new sequence (new place in memory) for that same type is created as a result of the concatenation. \n",
    "\n",
    "***Original sequences remain unchanged, new sequences made***\n",
    "\n",
    "To concat multiple copies of the same sequence, we can easily multiply it by an integer. Again saying above applies.\n",
    "\n",
    "`l = [1, 2, 3]`\n",
    "\n",
    "`l * 5`\n",
    "\n",
    "`print(l)`\n",
    "\n",
    "`>>>[1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3, 1, 2, 3]`\n",
    "\n",
    "**Warning** \n",
    "\n",
    "Because of this `+` and `*` always create a new object, and never change their operands. \n",
    "\n",
    "Beware of expressions like\n",
    "\n",
    "`a * n` \n",
    "\n",
    "Where a is a sequence containing mutable items, because the result may surprise you. For ex. Trying to init a list of lists with code like this below. Which results in a ist with 3 references to the same inner list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "fd91dd4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[], [], []]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# WARNING BAD CODE\n",
    "\n",
    "my_list = [[]] * 3\n",
    "my_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c6ac7c",
   "metadata": {},
   "source": [
    "**Building Lists of Lists**\n",
    "\n",
    "Sometimes to init a list with a certain number of nested lists - for ex. to distribute a students in a list of teams or to represent squares on a game board the best way of doing so is with list comp.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "f0016aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['_', '_', '_'], ['_', '_', '_'], ['_', '_', '_']]\n",
      "['_', '_', '_']\n",
      "[['_', '_', '_'], ['_', '_', 'X'], ['_', '_', '_']]\n"
     ]
    }
   ],
   "source": [
    "board = [[\"_\"] * 3 for i in range(3)]\n",
    "\n",
    "# 3x3 empty game board\n",
    "print(board)\n",
    "\n",
    "# is the code that multiplies the entry within\n",
    "# the list 3 times\n",
    "x = [\"_\"] * 3\n",
    "print(x)\n",
    "\n",
    "board[1][2] = \"X\"\n",
    "print(board)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4812a522",
   "metadata": {},
   "source": [
    "1. Created a list of three items each. Then checked structure.\n",
    "\n",
    "2. Placed a mark in row 1, column 2.\n",
    "\n",
    "The wrong way to do it is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "29449cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['_', '_', '_'], ['_', '_', '_'], ['_', '_', '_']]\n",
      "[['_', '_', 'X'], ['_', '_', 'X'], ['_', '_', 'X']]\n"
     ]
    }
   ],
   "source": [
    "bad_board = [[\"_\"] * 3] * 3\n",
    "# while it looks right..\n",
    "print(bad_board)\n",
    "\n",
    "# it has 3 references to the same list so its useless.\n",
    "bad_board[1][2] = \"X\"\n",
    "\n",
    "# not what we want..\n",
    "print(bad_board)\n",
    "\n",
    "# in essence it behaves like this code..\n",
    "row = [\"_\"] * 3\n",
    "board = []\n",
    "\n",
    "for i in range(3):\n",
    "    # same 'row' object is appended to board\n",
    "    board.append(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b909fe",
   "metadata": {},
   "source": [
    "On the other hand list comp behaves like the code below..\n",
    "\n",
    "1. Each iteration builds a new `row` and appends itself on to `board`\n",
    "\n",
    "2. No same reference bugs here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "ba26f5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "board = []\n",
    "for i in range(3):\n",
    "    # each iteration \n",
    "    row = [\"_\"] * 3\n",
    "    board.append(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2974770c",
   "metadata": {},
   "source": [
    "**Augmented Assignment with Sequences** \n",
    "\n",
    "The `+=` and `*=` behave quite differently, depending on the first operand. Whatever applies to `+=` will apply to `*=` etc.\n",
    "\n",
    "The special method that makes `+=` work is `__iadd__` (in place addition)\n",
    "\n",
    "However if `__iadd__` fails Python falls back to calling `__add__`. Consider this simple ex.\n",
    "\n",
    "`a += b`\n",
    "\n",
    "If a has implement `+=` then it will be called. In the case of mutable sequences (e.g. `list, bytearray, array.array`), a will be changed in place \n",
    "\n",
    "Changed in place means the expression will be similar to `a.extend(b)` \n",
    "\n",
    "If `a` **does NOT** have `+=` implemented it will be the same as the expression\n",
    "\n",
    "`a = a + b` \n",
    "\n",
    "the expression `a + b` is evaluated first producing a new object, which is then bound to `a`.\n",
    "\n",
    "In other words the identity of the object bound to `a` may or may not change depending on if `+=` is implemented.\n",
    "\n",
    "\n",
    "But in general for mutable sequences its fine to assume that `+=` is implemented and that it is equivalent to something like `a.extend(b)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "ef82c062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4389168960\n",
      "[1, 2, 3, 1, 2, 3]\n",
      "4389168960\n",
      "4631559360\n",
      "(1, 2, 3, 1, 2, 3)\n",
      "4391564192\n"
     ]
    }
   ],
   "source": [
    "l = [1, 2, 3]\n",
    "print(id(l))\n",
    "l *= 2 \n",
    "# similar to l.extend([1, 2, 3]) & changed in place\n",
    "print(l)\n",
    "print(id(l))\n",
    "\n",
    "# now with tuples.\n",
    "\n",
    "t = (1, 2, 3)\n",
    "print(id(t))\n",
    "\n",
    "# notice after multiplication new tuple was created\n",
    "t *= 2 \n",
    "print(t)\n",
    "print(id(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9167efe4",
   "metadata": {},
   "source": [
    "For obvious reasons repeated concatenation of immutable sequences (like `tuple`) is inefficient.\n",
    "\n",
    "The interpreter has to create a whole new object instead of just modifying the original target sequence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d86bd9d",
   "metadata": {},
   "source": [
    "**Edge Cases with the `+=` operator**\n",
    "\n",
    "Let's look at some weird outputs based on the `+=` operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "c5a4d4c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'tuple' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[214], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m t \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, [\u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m40\u001b[39m])\n\u001b[0;32m----> 2\u001b[0m \u001b[43mt\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m60\u001b[39m]\n",
      "\u001b[0;31mTypeError\u001b[0m: 'tuple' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "t = (1, 2, [30, 40])\n",
    "t[2] += [50, 60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bbb0b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, [30, 40, 50, 60])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Raised error for item assignment but..\n",
    "# item / list is modified in immutable sequence?\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5fa456b",
   "metadata": {},
   "source": [
    "From strange behavior like this it is a warning to:\n",
    "\n",
    "1. Avoid putting mutable items in tuples.\n",
    "\n",
    "2. Augmented assignment is not a atomic operation -- we just saw it throw and exception after doing part of its job \n",
    "\n",
    "3. Inspecting Python bytecode isn't too see what happens isn't a horrible idea."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d692971",
   "metadata": {},
   "source": [
    "**list.sort VS the sorted built-in**\n",
    "\n",
    "The `list.sort` methods sorts in place--that is, without making a copy. It returns `None` to remind us that it changes the receiver & does **NOT** make a new list. \n",
    "\n",
    "^ This is a crucial Python API convention: functions or methods that change an object in place **should** return `None` to make it clear to the caller that the receiver was changed.\n",
    "\n",
    "In contrast, the built-in function `sorted` creates a new list and returns it. It accepts **Any iterable object** as an arg, including immutable sequences and generators..\n",
    "\n",
    "Both however take two optional, keyword-only args:\n",
    "\n",
    "1. `reverse`: if `True` the items are returned descending oder (i.e from greatest to least). The default is `False`\n",
    "\n",
    "**more importantly**\n",
    "\n",
    "2. `key`: A one-arg function that will be applied to each item to produce its own sorting key. For ex, when sorting a list of strings, `key=str.lower` can be used to perform ***case-insensitive sort***, and `key=len` will sort the strings by character length..\n",
    "\n",
    "^ The default is the identity function (i.e, the items themselves are compared)\n",
    "\n",
    "***Note:*** You can also use the keyword parameter `key` with the `min()` and `max()` built-ins and with other functions from the standard library (e.g. `itertools.groupby() and `heapq.nlargest()`)\n",
    "\n",
    "These are some examples to show the use of the built in `sort()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1dcaeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['grape', 'raspberry', 'apple', 'banana']\n",
      "['apple', 'banana', 'grape', 'raspberry']\n",
      "Sorted by length: ['grape', 'apple', 'banana', 'raspberry']\n",
      "Sorted by their length (descending): ['raspberry', 'banana', 'grape', 'apple']\n"
     ]
    }
   ],
   "source": [
    "fruits =  ['grape', 'raspberry', 'apple', 'banana']\n",
    "new_fruits = sorted(fruits)\n",
    "\n",
    "# both different and exist\n",
    "print(fruits)\n",
    "print(new_fruits)\n",
    "\n",
    "new_fruits = sorted(fruits, key=len)\n",
    "# sorted by their length\n",
    "print(f\"Sorted by length: {new_fruits}\")\n",
    "\n",
    "new_fruits = sorted(fruits, key=len, reverse=True)\n",
    "print(f\"Sorted by their length (descending): {new_fruits}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "597234df",
   "metadata": {},
   "source": [
    "**When a List is Not the Answer**\n",
    "\n",
    "The `list` type is flexible and very easy to use, but depending on specific reqs, there are better options.\n",
    "\n",
    "For example an `array` saved a lot of memory when you need to handle millions of floating-point values. On the other hand, if you are constantly adding/removing items from opposite ends of a list, it's good to use a `deque` from python's standard library.\n",
    "\n",
    "This is some basic data structure shit to be honest.\n",
    "\n",
    "**Arrays**\n",
    "\n",
    "If a list only contains numbers, an `array.array` is a more efficient replacement. Arrays support all mutable sequence operations (including `.pop`, `.insert`, and `.extend`), as well as additional methods for very fast loading / saving.\n",
    "\n",
    "A Python array is as lean as a C array. An array of `float` values does not hold full fledged `float` instances, but only packed bytes representing their machine values-- similar to an array of `double` in the C language. \n",
    "\n",
    "When creating an `array` you provide a typecode, a letter to determine the underlying C type used to store each item in the array. For ex, `b` is the typecode for what C calls a `signed char`, an it ranging from -128 to 127. \n",
    "\n",
    "If you create an `array('b')` then each item will be stored in a single byte and interpreted as an integer. For larger sequences of numbers this saved a bunch of memory. Python also does some type safing as well because of this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6b8450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array('d', [0.9892777292048522, 0.4033524040657086, 0.8112342353416552])\n",
      "array('d', [0.9892777292048522, 0.4033524040657086, 0.8112342353416552])\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "from array import array\n",
    "from random import random\n",
    "\n",
    "floats = array(\"d\", (random() for i in range(10**7)))\n",
    "print(floats[0:3])\n",
    "\n",
    "fp = open(\"floats.bin\", \"wb\")\n",
    "floats.tofile(fp)\n",
    "fp.close()\n",
    "\n",
    "floats2 = array(\"d\")\n",
    "fp = open(\"floats.bin\", \"rb\")\n",
    "floats2.fromfile(fp, 10**7)\n",
    "fp.close()\n",
    "\n",
    "print(floats2[0:3])\n",
    "print(floats == floats2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec48275",
   "metadata": {},
   "source": [
    "1. Imported the array type\n",
    "\n",
    "2. Create an array of double-precision floats (typecode `'d'`) from any iterable object -- (in this case a generator expression)\n",
    "\n",
    "3. Inspect the first 3 digits in the array.\n",
    "\n",
    "4. Save the array to a binary file\n",
    "\n",
    "5. Create an empty array of doubles\n",
    "\n",
    "6. Read the 10 million numbers from the binary file.\n",
    "\n",
    "7. Inspect the first 3 elements in the array.\n",
    "\n",
    "8. Verify their the same (element wise)\n",
    "\n",
    "***Note:*** `array.tofile` and `array.fromfile` are extremely fast. If you test it the code takes 0.1 seconds to load 10 million double precision floats. Something 600 times faster than reading numbers from a text file.\n",
    "\n",
    "To learn more check out `array.array` docs.\n",
    "\n",
    "\n",
    "**Memory Views**\n",
    "\n",
    "The built-in `memoryview` class is a shared memory sequence type that lets you handle slices of arrays without copying bytes.\n",
    "\n",
    "A memoryview can be viewed as a generalized NumPy array structure in Python itself (without all the mathy stuff). It allows you to share memory between data structures (things like `PIL` images of SQLite databases, NumPy arrays, etc.) *without first copying* something crucial for large datasets.\n",
    "\n",
    "Using notation similar to the `array` module, the `memoryview.cast` method lets you change the way multiple bytes are read or written as units without moving bits around. `memoryview.cast` returns yet another `memoryview` object, always sharing the same memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33a3f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5]\n",
      "[[0, 1, 2], [3, 4, 5]]\n",
      "[[0, 1], [2, 3], [4, 5]]\n",
      "m2 changed: [[0, 1, 2], [33, 22, 5]]\n",
      "m3 changed: [[0, 1], [2, 33], [22, 5]]\n",
      "\n",
      "This ALL changed m1:\n",
      "array('B', [0, 1, 2, 33, 22, 5])\n"
     ]
    }
   ],
   "source": [
    "from array import array\n",
    "octets = array('B', range(6))\n",
    "m1 = memoryview(octets)\n",
    "\n",
    "# show m1\n",
    "print(m1.tolist())\n",
    "\n",
    "# make new memory view w/ 2 rows and 3 columns\n",
    "m2 = m1.cast('B', [2, 3])\n",
    "print(m2.tolist())\n",
    "\n",
    "# again new memory view from m1 (3 rows, 2 columns)\n",
    "m3 = m1.cast('B', [3, 2])\n",
    "print(m3.tolist())\n",
    "\n",
    "# modified m2 and m3\n",
    "m2[1, 1] = 22 # row 1 col 1 changed\n",
    "m3[1, 1] = 33\n",
    "\n",
    "print(f\"m2 changed: {m2.tolist()}\\nm3 changed: {m3.tolist()}\")\n",
    "print(f\"\\nThis ALL changed m1:\\n{octets}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2483210b",
   "metadata": {},
   "source": [
    "1. Build an array of 6 bytes (typecode 'B')\n",
    "\n",
    "2. Build memoryview frp, that array, then export it as `list`\n",
    "\n",
    "3. Build new memoryview from prev one but with 2 rows and 3 columns..\n",
    "\n",
    "4. Yet another memoryview, now with 3 rows and 2 columns.\n",
    "\n",
    "5. Overwrite byte in `m2` at row 1 column 1 with 22.\n",
    "\n",
    "6. Overwrite byte in `m3`\n",
    "\n",
    "7. Display og array to show memory was shared among `octets`, `m1`, `m2`, and `m3`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d695863a",
   "metadata": {},
   "source": [
    "**NumPy**\n",
    "\n",
    "Let's take a quick reintroduction to `numpy` just because of how neat it is and helpful it is for both quant/ML use, but also scientific computing. Here are some high lvl operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff61cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11] <class 'numpy.ndarray'> (12,)\n",
      "Changed a shape:\n",
      "(array([[ 0,  1,  2,  3],\n",
      "       [ 4,  5,  6,  7],\n",
      "       [ 8,  9, 10, 11]]), <class 'numpy.ndarray'>)\n",
      "[ 8  9 10 11]\n",
      "[ 8  9 10 11]\n",
      "[1 5 9]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "a = np.arange(12)\n",
    "print(a, type(a), a.shape)\n",
    "\n",
    "a.shape = (3, 4)\n",
    "print(f\"Changed a shape:\\n{a, type(a)}\")\n",
    "\n",
    "# get row last of the 3x4 array \n",
    "print(a[2])\n",
    "print(a[-1])\n",
    "\n",
    "# get columns of a (column 1)\n",
    "print(a[:, 1])\n",
    "\n",
    "# of course\n",
    "print(f\"\\nTranspose of A: {a.T}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d266d0",
   "metadata": {},
   "source": [
    "### Summary of Chapter 2\n",
    "\n",
    "The most important things to know from this chapter since some of the notes of the chapter were not included are..\n",
    "\n",
    "1. Every Python object in memory has a header with metadata. The simplest Python object, a `float`, has a value field and two metadeta fields.\n",
    "\n",
    "- `ob_refcnt:` the object’s reference count\n",
    "- `ob_type:` a pointer to the object’s type\n",
    "- `ob_fval:` a C `double` holding the value of the float.\n",
    "\n",
    "On a 64-bit Python build, each of those fields takes 8 bytes. That’s why an array of floats is much more compact than a tuple of floats:\n",
    "\n",
    "the array is a single object holding the raw values of the floats, while the tuple contains several objects—the tuple itself (ob_type reference) and each float object contained in it. \n",
    "\n",
    "Another way of grouping sequence types is by mutability:\n",
    "\n",
    "*Mutable Sequences*\n",
    "\n",
    "For example, `list, bytearray, array.array,` and `collections.deque`\n",
    "\n",
    "*Immutable Sequences*\n",
    "\n",
    "For example, `tuple, str,` and `bytes`\n",
    "\n",
    "Always keep in mind: mutable v immutable; container v flat.\n",
    "\n",
    "**Generator Expressions are Crucial!**\n",
    "\n",
    "In Python code, line breaks are ignored inside pairs of [], {}, or ().\n",
    "So you can build multiline lists, listcomps, tuples, dictionaries, etc.,\n",
    "without using the \\ line continuation escape, which doesn’t work if\n",
    "you accidentally type a space after it. Also, when those delimiter\n",
    "pairs are used to define a literal with a comma-separated series of\n",
    "items, a trailing comma will be ignored. So, for example, when cod‐\n",
    "ing a multiline list literal, it is thoughtful to put a comma after the\n",
    "last item, making it a little easier for the next coder to add one\n",
    "more item to that list, and reducing noise when reading diffs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05350e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\"white\", \"black\"]\n",
    "sizes = [\"S\", \"M\", \"L\"] \n",
    "tshirts = [(color, size) for color in colors for size in sizes]\n",
    "print(tshirts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9654b9",
   "metadata": {},
   "source": [
    "**The Generator Expressions**\n",
    "\n",
    "To init tuples, arrays, and other types of sequences, you could also start from listcomp, but a genexp saves memory because it yields items one by one using the iterator protocol instead of building a whole list to just feed it into another type constructor. \n",
    "\n",
    "Genexps use the same syntax as listcomps, but are enclosed in parentheses rather than brackets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5e93b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuple built of genexps: (36, 162, 163, 165, 8364, 164)\n"
     ]
    }
   ],
   "source": [
    "# init a tuple and an array from a generator expression\n",
    "symbols = \"$¢£¥€¤\"\n",
    "x = tuple(ord(symbol) for symbol in symbols)\n",
    "print(f\"tuple built of genexps: {x}\")\n",
    "\n",
    "import array\n",
    "# the \"i\" defines storage type while learn more abt this soon\n",
    "y = array.array(\"I\", (ord(symbol) for symbol in symbols) )\n",
    "print(f\"array built on genexps: {y}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccf520a",
   "metadata": {},
   "source": [
    "## Chapter 3: Dictionaries and Sets \n",
    "\n",
    "*Hash tables* are the engines behind Python's high-performanced `dict`. With many other built-in types based on hash tables like `set` and `frozenset` \n",
    "\n",
    "**Modern dict Syntax**\n",
    "\n",
    "The syntax of listcomps and genexps was adapted to `dict` comprehensions (and `set` comprehensions as well). A *dictcomp* just builds a `dict` instance from any iterable. Let's look at an ex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc53c9e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Bangladesh': 880, 'Brazil': 55, 'China': 86, 'India': 91, 'Indonesia': 62, 'Japan': 81, 'Nigeria': 234, 'Pakistan': 92, 'Russia': 7, 'United States': 1}\n",
      "\n",
      "advanced dict comp results: {'BRAZIL': 55, 'INDONESIA': 62, 'RUSSIA': 7, 'UNITED STATES': 1}\n"
     ]
    }
   ],
   "source": [
    "dial_codes = [\n",
    "    (880, 'Bangladesh'),\n",
    "    (55, 'Brazil'),\n",
    "    (86, 'China'),\n",
    "    (91, 'India'),\n",
    "    (62, 'Indonesia'),\n",
    "    (81, 'Japan'),\n",
    "    (234, 'Nigeria'),\n",
    "    (92, 'Pakistan'),\n",
    "    (7, 'Russia'),\n",
    "    (1, 'United States'),\n",
    "]\n",
    "\n",
    "country_dial = {country: code for code, country in dial_codes}\n",
    "print(country_dial)\n",
    "\n",
    "# could make this even better\n",
    "country_dial = {country.upper(): code for country, code in \n",
    "                sorted(country_dial.items()) if code < 70}\n",
    "\n",
    "print(f\"\\nadvanced dict comp results: {country_dial}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ef8fab",
   "metadata": {},
   "source": [
    "**Unpacking Mappings / Dict Unpacking** \n",
    "\n",
    "We can apply `**` to more than one argument in a function call. This works when keys are all strings and unique across all arguments (duplicate keys not allowed.)\n",
    "\n",
    "When the `**` unpacking operator is used in function calls or dictionary displays, it unpacks a dictionary's key-value pairs as key word argument or into another dictionary as seen here below..\n",
    "\n",
    "Notice as well here even duplicate keys are allowed when used in a `dict` literal, because unpacking just overwrites previous keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b677c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x': 1, 'y': 2, 'z': 3}\n",
      "{'a': 0, 'x': 4, 'y': 2, 'z': 3}\n",
      "tootles! Alice!\n",
      "\n",
      "merged dict: {'a': 1, 'b': 2, 'c': 3, 'd': 4}\n"
     ]
    }
   ],
   "source": [
    "def dump(**kwargs):\n",
    "    return kwargs\n",
    "\n",
    "a = dump(**{'x': 1}, y=2, **{'z': 3})\n",
    "print(a)\n",
    "\n",
    "# also ** can be used in a dict literal - multiple times\n",
    "b = {'a': 0, **{'x': 1}, 'y': 2, **{'z':3, 'x': 4}}\n",
    "print(b)\n",
    "\n",
    "def greet(name, greeting='Hello'):\n",
    "    print(f\"{greeting} {name}!\")\n",
    "\n",
    "person_data = {\"name\": \"Alice\", \"greeting\": \"tootles!\"}\n",
    "greet(**person_data)\n",
    "\n",
    "d1, d2 = {'a': 1, 'b': 2}, {'c': 3, 'd': 4}\n",
    "merged_d = {**d1, **d2}\n",
    "print(f'\\nmerged dict: {merged_d}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9e7ee0",
   "metadata": {},
   "source": [
    "**Merging Mappings / Dicts with |**\n",
    "\n",
    "As we just saw we can merge dicts in a `dict` literal with the use of the `**` unpacking operator.\n",
    "\n",
    "However Python 3.9 also allows to use `|` or `|=` to merge mappings/dictionaries. This makes sense are their the union operators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9913f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'a': 2, 'b': 4, 'c': 6}\n",
      "{'a': 1, 'b': 3}\n"
     ]
    }
   ],
   "source": [
    "d1 = {'a': 1, 'b': 3}\n",
    "d2 = {'a': 2, 'b': 4, 'c': 6}\n",
    "\n",
    "# Notice - overwritten previous keys\n",
    "print(d1 | d2)\n",
    "\n",
    "\n",
    "# Notice - d1 unchanged.\n",
    "print(d1)\n",
    "\n",
    "# Can also be used to update and existing mapping in place\n",
    "d1 |= d2\n",
    "print(d1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e875d2",
   "metadata": {},
   "source": [
    "**Standard API of Mapping Types**\n",
    "\n",
    "The `collections.abc` module provides the `Mapping` and `MutableMapping` ABCs describing the interfaces of `dict` and similar types.\n",
    "\n",
    "The main value of the ABCs is **the documenting and formalizing the standard interfaces for mappings**, and serving as criteria for `isinstance` tests in code that needs to support mappings in a broad sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33d11f8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "from collections import abc\n",
    "my_dict = {}\n",
    "print(isinstance(my_dict, abc.Mapping))\n",
    "print(isinstance(my_dict, abc.MutableMapping))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b439b225",
   "metadata": {},
   "source": [
    "To implement a custom mapping its easier to extend `collections.UserDict` or to wrap a `dict` by composition, instead of subclassing these ABCs. \n",
    "\n",
    "the `collections.UserDict` class has all concrete mapping classes and the basic `dict` implementation, which is built on a hash table.\n",
    "\n",
    "**What is hashable**\n",
    "\n",
    "Remember that all keys in a `dict` must be hashable and from the *Python Glossary*\n",
    "\n",
    "*An object is hashable if the hash code never changes during its lifetime (it also needs a `__hash__()` method), and can be compared to other objects (it needs a `__eq__()` method). Hashable. objects which compare equal must have the same hash code.*\n",
    "\n",
    "Of course, numeric and flat immutable types (`str`, `int`) all hashable. Container types *CAN BE* hashable if all contained objects are also hashable. \n",
    "\n",
    "A `tuple` for ex. is hashable if it has hashable items in it.\n",
    "\n",
    "`tl = (1, 2, [30, 40])` <= would throw error.\n",
    "\n",
    "User-defined types are hashable by def b/c their hash-code is their `id()`, and the `__eq__()` method inherited from the `object` class simply compares the object IDs. \n",
    "\n",
    "^ ***Note:*** Of course this changes if you implement your own `__eq__()` method but it still is hashable if `__hash__()` always returns the same hash code.\n",
    "\n",
    "\n",
    "**Overview of Common Mapping Methods**\n",
    "\n",
    "The basic API for mappings is quite rich, the table shows the methods implemented by `dict` and two popular variations: `defaultdict` and `OrderedDict` both from `collections`\n",
    "\n",
    "\n",
    "*Dictionary Methods Comparison*\n",
    "\n",
    "\n",
    "\n",
    "| Method | dict | defaultdict | OrderedDict | Description |\n",
    "|--------|------|-------------|-------------|-------------|\n",
    "| `d.clear()` | ● | ● | ● | Remove all items |\n",
    "| `d.__contains__(k)` | ● | ● | ● | `k in d` |\n",
    "| `d.copy()` | ● | ● | ● | Shallow copy |\n",
    "| `d.__copy__()` | | | ● | Support for `copy.copy(d)` |\n",
    "| `d.default_factory` | | ● | | Callable invoked by `__missing__` to set missing values |\n",
    "| `d.__delitem__(k)` | ● | ● | ● | `del d[k]` - remove item with key k |\n",
    "| `d.fromkeys(it, [initial])` | ● | ● | ● | New mapping from keys in iterable, with optional initial value (defaults to None) |\n",
    "| `d.get(k, [default])` | ● | ● | ● | Get item with key k, return default or None if missing |\n",
    "| `d.__getitem__(k)` | ● | ● | ● | `d[k]` - get item with key k |\n",
    "| `d.items()` | ● | ● | ● | Get view over items - (key, value) pairs |\n",
    "| `d.__iter__()` | ● | ● | ● | Get iterator over keys |\n",
    "| `d.keys()` | ● | ● | ● | Get view over keys |\n",
    "| `d.__len__()` | ● | ● | ● | `len(d)` - number of items |\n",
    "| `d.__missing__(k)` | | ● | | Called when `__getitem__` cannot find the key |\n",
    "| `d.move_to_end(k, [last])` | | | ● | Move k first or last position (last is True by default) |\n",
    "| `d.__or__(other)` | ● | ● | ● | Support for `d1 \\| d2` to create new dict merging d1 and d2 (Python ≥ 3.9) |\n",
    "| `d.__ior__(other)` | ● | ● | ● | Support for `d1 \\|= d2` to update d1 with d2 (Python ≥ 3.9) |\n",
    "| `d.pop(k, [default])` | ● | ● | ● | Remove and return value at k, or default or None if missing |\n",
    "| `d.popitem()` | ● | ● | ● | Remove and return the last inserted item as (key, value) |\n",
    "| `d.__reversed__()` | ● | ● | ● | Support for `reverse(d)` - returns iterator for keys from last to first inserted |\n",
    "| `d.__ror__(other)` | ● | ● | ● | Support for `other \\| d` - reversed union operator (Python ≥ 3.9) |\n",
    "| `d.setdefault(k, [default])` | ● | ● | ● | If k in d, return d[k]; else set d[k] = default and return it |\n",
    "| `d.__setitem__(k, v)` | ● | ● | ● | `d[k] = v` - put v at k |\n",
    "| `d.update(m, [**kwargs])` | ● | ● | ● | Update d with items from mapping or iterable of (key, value) pairs |\n",
    "| `d.values()` | ● | ● | ● | Get view over values |\n",
    "\n",
    "### Key Differences:\n",
    "- **defaultdict**: Has `default_factory` and `__missing__` for automatic value creation\n",
    "- **OrderedDict**: Has `move_to_end()` and `__copy__()` for order manipulation\n",
    "- **dict**: Standard implementation with all basic functionality\n",
    "\n",
    "The way `d.update(m)` handles its first argument `m` is a prime example of *duck typing* it first checks whether `m` has keys method and, if it does, assumes it is a mapping.\n",
    "\n",
    "Otherwise, `update()` falls back to iterating over m, assuming its items are `(key, value)` pairs.\n",
    "\n",
    "The constructor for most Python mappings uses the logic of `update()` internally, which means they can be initialized from other mappings or from any other iterable object producing `(key, value)` pairs.\n",
    "\n",
    "`setdefault()` avoids redundant key lookups when we need to update the value of an item in place. The next section shows a bit more about it.\n",
    "\n",
    "**Inserting or Updating Mutable Values**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
